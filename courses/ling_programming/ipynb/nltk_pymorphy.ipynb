{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4056b54",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddb64d",
   "metadata": {},
   "source": [
    "Токенизация: деление на т.н. \"токены\" &ndash; какие-либо значимые элементы:\n",
    "\n",
    "1. Предложения\n",
    "2. Слова\n",
    "3. Морфемы\n",
    "4. Графемы\n",
    "5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb232a",
   "metadata": {},
   "source": [
    "По каким признакам можно делить на предложения? Какие могут быть проблемы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2923cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db719858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Был тихий серый вечер.', '\"Кто это?', '\", спросил мальчик, заглядывая на следующую страницу.']\n"
     ]
    }
   ],
   "source": [
    "text = 'Был тихий серый вечер. \"Кто это?\", спросил мальчик, заглядывая на следующую страницу.'\n",
    "\n",
    "sentences = nltk.tokenize.sent_tokenize(text, \"russian\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018271c",
   "metadata": {},
   "source": [
    "https://aclanthology.org/J06-4003.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb70532",
   "metadata": {},
   "source": [
    "Какие могут возникнуть проблемы при делении на слова?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b82d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Был', 'тихий', 'серый', 'вечер', '.']\n",
      "['``', 'Кто', 'это', '?']\n",
      "['``', ',', 'спросил', 'мальчик', ',', 'заглядывая', 'на', 'следующую', 'страницу', '.']\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    print(nltk.tokenize.word_tokenize(sent, \"russian\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0645e",
   "metadata": {},
   "source": [
    "Токенизация с помощью регулярных выражений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "095bfba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Был',\n",
       " 'тихий',\n",
       " 'серый',\n",
       " 'вечер',\n",
       " 'Кто',\n",
       " 'это',\n",
       " 'спросил',\n",
       " 'мальчик',\n",
       " 'заглядывая',\n",
       " 'на',\n",
       " 'следующую',\n",
       " 'страницу']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461e2744",
   "metadata": {},
   "source": [
    "### Стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9fd03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "был\n",
      "тих\n",
      "сер\n",
      "вечер\n",
      "дул\n",
      "ветер\n",
      "слаб\n",
      "и\n",
      "тепл\n",
      "неб\n",
      "был\n",
      "покрыт\n",
      "туч\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "text = \"был тихий серый вечер дул ветер слабый и тёплый небо было покрыто тучами\"\n",
    "for word in text.split():\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b03933",
   "metadata": {},
   "source": [
    "#### Проблемы стемминга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e9e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ветер\n",
      "ветр\n"
     ]
    }
   ],
   "source": [
    "# чередование в основах\n",
    "print(stemmer.stem(\"ветер\"))\n",
    "print(stemmer.stem(\"ветра\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8430c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "банк\n",
      "банк\n"
     ]
    }
   ],
   "source": [
    "# омонимия основ\n",
    "print(stemmer.stem(\"банком\"))\n",
    "print(stemmer.stem(\"банкой\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c0c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "человек\n",
      "люд\n"
     ]
    }
   ],
   "source": [
    "# супплетивизм\n",
    "print(stemmer.stem(\"человек\"))\n",
    "print(stemmer.stem(\"люди\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d89dae",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1758219",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c452853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3 as pymorphy\n",
    "morph = pymorphy.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f8e55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "быть\n",
      "тихий\n",
      "серый\n",
      "вечер\n",
      "дуть\n",
      "ветер\n",
      "слабый\n",
      "и\n",
      "тёплый\n",
      "небо\n",
      "быть\n",
      "покрыть\n",
      "туча\n"
     ]
    }
   ],
   "source": [
    "for word in text.split():\n",
    "    print(morph.parse(word)[0].normal_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd37439d",
   "metadata": {},
   "source": [
    "Проверим проблемные места:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a838d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ветер\n",
      "ветер\n"
     ]
    }
   ],
   "source": [
    "print(morph.parse(\"ветер\")[0].normal_form)\n",
    "print(morph.parse(\"ветра\")[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a501f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "банк\n",
      "банка\n"
     ]
    }
   ],
   "source": [
    "print(morph.parse(\"банком\")[0].normal_form)\n",
    "print(morph.parse(\"банкой\")[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39264cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "человек\n",
      "человек\n"
     ]
    }
   ],
   "source": [
    "print(morph.parse(\"человек\")[0].normal_form)\n",
    "print(morph.parse(\"люди\")[0].normal_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f844a04",
   "metadata": {},
   "source": [
    "### Морфологический анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f385430",
   "metadata": {},
   "source": [
    "https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html\n",
    "\n",
    "В pymoprhy используются граммемы OpenCorpora с небольшими изменениями:\n",
    "\n",
    "https://opencorpora.org/dict.php?act=gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0244ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in text.split():\n",
    "    print(morph.parse(word)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338345c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='тихий', tag=OpencorporaTag('ADJF,Qual inan,masc,sing,accs'), normal_form='тихий', score=0.666666, methods_stack=((DictionaryAnalyzer(), 'тихий', 738, 4),)),\n",
       " Parse(word='тихий', tag=OpencorporaTag('ADJF,Qual masc,sing,nomn'), normal_form='тихий', score=0.333333, methods_stack=((DictionaryAnalyzer(), 'тихий', 738, 0),))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsres = morph.parse(\"тихий\")\n",
    "parsres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c09bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='курдячит', tag=OpencorporaTag('VERB,impf,intr sing,3per,pres,indc'), normal_form='курдячать', score=0.5384615384615384, methods_stack=((DictionaryAnalyzer(), 'ячит', 564, 5), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'курд'))),\n",
       " Parse(word='курдячит', tag=OpencorporaTag('VERB,impf,intr sing,3per,pres,indc'), normal_form='курдячить', score=0.23076923076923075, methods_stack=((FakeDictionary(), 'курдячит', 371, 5), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'ячит'))),\n",
       " Parse(word='курдячит', tag=OpencorporaTag('VERB,perf,intr sing,3per,futr,indc'), normal_form='курдячить', score=0.23076923076923075, methods_stack=((FakeDictionary(), 'курдячит', 1551, 9), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'ячит')))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsres = morph.parse(\"курдячит\")\n",
    "parsres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb84df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count',\n",
       " 'index',\n",
       " 'inflect',\n",
       " 'is_known',\n",
       " 'lexeme',\n",
       " 'make_agree_with_number',\n",
       " 'methods_stack',\n",
       " 'normal_form',\n",
       " 'normalized',\n",
       " 'score',\n",
       " 'tag',\n",
       " 'word']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[i for i in dir(parsres[0]) if not i.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsres[0].lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5297dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parse(word='тихую', tag=OpencorporaTag('ADJF,Qual femn,sing,accs'), normal_form='тихий', score=1.0, methods_stack=((DictionaryAnalyzer(), 'тихую', 738, 10),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsres[0].inflect({\"femn\", \"accs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8aa63e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJF,Qual inan,masc,sing,accs\n"
     ]
    }
   ],
   "source": [
    "tag = morph.parse(\"тихий\")[0].tag\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "457dccb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANIMACY',\n",
       " 'ASPECTS',\n",
       " 'CASES',\n",
       " 'FORMAT',\n",
       " 'GENDERS',\n",
       " 'INVOLVEMENT',\n",
       " 'KNOWN_GRAMMEMES',\n",
       " 'MOODS',\n",
       " 'NUMBERS',\n",
       " 'PARTS_OF_SPEECH',\n",
       " 'PERSONS',\n",
       " 'POS',\n",
       " 'RARE_CASES',\n",
       " 'TENSES',\n",
       " 'TRANSITIVITY',\n",
       " 'VOICES',\n",
       " '_CYR2LAT',\n",
       " '_EXTRA_INCOMPATIBLE',\n",
       " '_GRAMMEME_INCOMPATIBLE',\n",
       " '_GRAMMEME_INDICES',\n",
       " '_LAT2CYR',\n",
       " '_NON_PRODUCTIVE_GRAMMEMES',\n",
       " '_NUMERAL_AGREEMENT_GRAMMEMES',\n",
       " '_POS',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__firstlineno__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__static_attributes__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_assert_grammemes_are_known',\n",
       " '_assert_grammemes_initialized',\n",
       " '_cyr',\n",
       " '_cyr_grammemes_cache',\n",
       " '_from_internal_grammeme',\n",
       " '_from_internal_tag',\n",
       " '_grammemes_cache',\n",
       " '_grammemes_tuple',\n",
       " '_init_grammemes',\n",
       " '_is_unknown',\n",
       " '_str',\n",
       " 'add_grammemes_to_known',\n",
       " 'animacy',\n",
       " 'aspect',\n",
       " 'case',\n",
       " 'cyr2lat',\n",
       " 'cyr_repr',\n",
       " 'fix_rare_cases',\n",
       " 'gender',\n",
       " 'grammeme_is_known',\n",
       " 'grammemes',\n",
       " 'grammemes_cyr',\n",
       " 'involvement',\n",
       " 'is_productive',\n",
       " 'lat2cyr',\n",
       " 'mood',\n",
       " 'number',\n",
       " 'numeral_agreement_grammemes',\n",
       " 'person',\n",
       " 'tense',\n",
       " 'transitivity',\n",
       " 'typed_grammemes',\n",
       " 'updated_grammemes',\n",
       " 'voice']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fd3c2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJF sing accs masc\n"
     ]
    }
   ],
   "source": [
    "print(tag.POS, tag.number, tag.case, tag.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f95979d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ADJF\" in tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89ee9454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"NOUN\" in tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06933524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"accs\", \"sing\"} in tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e6326da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpencorporaTag('PNCT')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse(\".\")[0].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae2297",
   "metadata": {},
   "source": [
    "### Задания для самостоятельного выполнения\n",
    "\n",
    "#### Задание 1: токенизация на графемы\n",
    "\n",
    "Даны два текста на русском языке в транскрипции с разными обозначениями.\n",
    "\n",
    "* https://pkholyavin.github.io/year4programming/sibling_sample.txt\n",
    "* https://pkholyavin.github.io/year4programming/corpres_sample.txt\n",
    "\n",
    "1. Для каждого текста внимательно изучить принятые обозначения, определить, в каком случае возможна однозначная токенизация, а в каком невозможна, и почему.\n",
    "2. Для текста, в котором она возможна, написать программу, которая каждую строчку превращает в список звуков. Бонусные очки, если сделаете с помощью регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://phonetics-spbu.github.io/courses/ling_programming/files/sibling_sample.txt\n",
    "!wget -q https://phonetics-spbu.github.io/courses/ling_programming/files/corpres_sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91050fa5",
   "metadata": {},
   "source": [
    "#### Задание 2 + домашнее задание\n",
    "\n",
    "1. Возьмите любой текст (например, новостной или скачать с wikisource или lib.ru)\n",
    "2. С помощью nltk разбейте текст на предложения, каждое предложение разбить на слова.\n",
    "3. Постройте словари слов: алфавитный список, частотный словарь, частотный словарь лексем.\n",
    "4. Постройте алфавитный список всех глаголов. Каждый глагол поставьте в форму первого лица, единственного числа и настоящего времени, если глагол несовершенного вида, и будущего, если он совершенного вида."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
