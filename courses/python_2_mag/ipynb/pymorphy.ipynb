{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZt0m13gDc78",
        "outputId": "8c88b883-81d8-4a97-ead4-23641cb508ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.12/dist-packages (2.0.6)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (75.2.0)\n"
          ]
        }
      ],
      "source": [
        "# Установка\n",
        "!pip install pymorphy3\n",
        "\n",
        "# Импорт и инициализация\n",
        "import pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "# разбор слова\n",
        "word = \"стали\"\n",
        "parsed = morph.parse(word)\n",
        "print(f\"Разбор слова '{word}':\")\n",
        "for i, analysis in enumerate(parsed):\n",
        "    print(f\"{i+1}. {analysis}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1hCRLVMDweY",
        "outputId": "b95010f8-e0d9-450c-86c9-bc6ffa66fc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Разбор слова 'стали':\n",
            "1. Parse(word='стали', tag=OpencorporaTag('VERB,perf,intr plur,past,indc'), normal_form='стать', score=0.975342, methods_stack=((DictionaryAnalyzer(), 'стали', 945, 4),))\n",
            "2. Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='сталь', score=0.010958, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 1),))\n",
            "3. Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='сталь', score=0.005479, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 6),))\n",
            "4. Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 2),))\n",
            "5. Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 5),))\n",
            "6. Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 9),))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html"
      ],
      "metadata": {
        "id": "tdXSPfGLD8Gn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Структура разбора"
      ],
      "metadata": {
        "id": "gaysnLmlEhmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"бежал\"\n",
        "parsed_word = morph.parse(word)[0]  # Берем наиболее вероятный вариант\n",
        "\n",
        "print(f\"Слово: {parsed_word.word}\")\n",
        "print(f\"Нормальная форма: {parsed_word.normal_form}\")\n",
        "print(f\"Часть речи: {parsed_word.tag.POS}\")\n",
        "print(f\"Падеж: {parsed_word.tag.case}\")\n",
        "print(f\"Число: {parsed_word.tag.number}\")\n",
        "print(f\"Время: {parsed_word.tag.tense}\")\n",
        "print(f\"Полный тег: {parsed_word.tag}\")\n",
        "print(f\"Склоняемость: {parsed_word.tag.animacy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqkjQb7xD83V",
        "outputId": "8cd5771d-4985-4650-facf-7e195b38249a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слово: бежал\n",
            "Нормальная форма: бежать\n",
            "Часть речи: VERB\n",
            "Падеж: None\n",
            "Число: sing\n",
            "Время: past\n",
            "Полный тег: VERB,perf,intr masc,sing,past,indc\n",
            "Склоняемость: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работа с множественными разборами"
      ],
      "metadata": {
        "id": "6hZ1a4LMEjKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_word(word):\n",
        "    analyses = morph.parse(word)\n",
        "    print(f\"Все варианты разбора слова '{word}':\")\n",
        "    for i, analysis in enumerate(analyses, 1):\n",
        "        print(f\"{i}. НФ: {analysis.normal_form:15} | \"\n",
        "              f\"ЧР: {str(analysis.tag.POS):10} | \"\n",
        "              f\"Вероятность: {analysis.score:.3f}\")\n",
        "\n",
        "# Тестируем на омонимах\n",
        "analyze_word(\"ключ\")\n",
        "analyze_word(\"печь\")\n",
        "analyze_word(\"стекло\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXNRDEtMEQRc",
        "outputId": "d7e59340-cbd6-410d-ac38-b50f1d2213f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Все варианты разбора слова 'ключ':\n",
            "1. НФ: ключ            | ЧР: NOUN       | Вероятность: 0.769\n",
            "2. НФ: ключ            | ЧР: NOUN       | Вероятность: 0.231\n",
            "Все варианты разбора слова 'печь':\n",
            "1. НФ: печь            | ЧР: NOUN       | Вероятность: 0.571\n",
            "2. НФ: печь            | ЧР: INFN       | Вероятность: 0.286\n",
            "3. НФ: печь            | ЧР: NOUN       | Вероятность: 0.143\n",
            "Все варианты разбора слова 'стекло':\n",
            "1. НФ: стекло          | ЧР: NOUN       | Вероятность: 0.690\n",
            "2. НФ: стекло          | ЧР: NOUN       | Вероятность: 0.286\n",
            "3. НФ: стечь           | ЧР: VERB       | Вероятность: 0.024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Извлечение морфологических признаков"
      ],
      "metadata": {
        "id": "K4B8oUrBEpYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_morph_features(word):\n",
        "    parsed = morph.parse(word)[0]\n",
        "    features = {\n",
        "        'слово': parsed.word,\n",
        "        'лемма': parsed.normal_form,\n",
        "        'часть_речи': parsed.tag.POS,\n",
        "        'падеж': parsed.tag.case,\n",
        "        'число': parsed.tag.number,\n",
        "        'род': parsed.tag.gender,\n",
        "        'время': parsed.tag.tense,\n",
        "        'залог': parsed.tag.voice,\n",
        "        'наклонение': parsed.tag.mood\n",
        "    }\n",
        "    return {k: v for k, v in features.items() if v is not None}\n",
        "\n",
        "# Примеры\n",
        "words = [\"столом\", \"писала\", \"красивая\", \"бежали\"]\n",
        "for word in words:\n",
        "    features = get_morph_features(word)\n",
        "    print(f\"{word}: {features}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pnWjkgREcJO",
        "outputId": "2ea034c8-36b3-4025-b6d0-d50e07da8f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "столом: {'слово': 'столом', 'лемма': 'стол', 'часть_речи': 'NOUN', 'падеж': 'ablt', 'число': 'sing', 'род': 'masc'}\n",
            "писала: {'слово': 'писала', 'лемма': 'писать', 'часть_речи': 'VERB', 'число': 'sing', 'род': 'femn', 'время': 'past', 'наклонение': 'indc'}\n",
            "красивая: {'слово': 'красивая', 'лемма': 'красивый', 'часть_речи': 'ADJF', 'падеж': 'nomn', 'число': 'sing', 'род': 'femn'}\n",
            "бежали: {'слово': 'бежали', 'лемма': 'бежать', 'часть_речи': 'VERB', 'число': 'plur', 'время': 'past', 'наклонение': 'indc'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Базовая лемматизация"
      ],
      "metadata": {
        "id": "AtlchmgEEx-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    lemmas = []\n",
        "\n",
        "    for word in words:\n",
        "        # Убираем знаки препинания\n",
        "        clean_word = ''.join(char for char in word if char.isalpha())\n",
        "        if clean_word:\n",
        "            parsed = morph.parse(clean_word)[0]\n",
        "            lemmas.append(parsed.normal_form)\n",
        "\n",
        "    return lemmas\n",
        "\n",
        "text = \"Машины ехали по дорогам, обгоняя друг друга\"\n",
        "lemmas = lemmatize_text(text)\n",
        "print(f\"Исходный текст: {text}\")\n",
        "print(f\"Леммы: {lemmas}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdCDdjQyE25q",
        "outputId": "21fcc632-3c5c-4b7f-cd38-133dd325ea1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Машины ехали по дорогам, обгоняя друг друга\n",
            "Леммы: ['машина', 'ехать', 'по', 'дорога', 'обгонять', 'друг', 'друг']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лемматизация с учетом признаков"
      ],
      "metadata": {
        "id": "ThWnQWiUE6jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smart_lemmatize(word, pos=None):\n",
        "    analyses = morph.parse(word)\n",
        "\n",
        "    if pos:\n",
        "        # Фильтруем по части речи\n",
        "        for analysis in analyses:\n",
        "            if analysis.tag.POS == pos:\n",
        "                return analysis.normal_form\n",
        "\n",
        "    # Возвращаем наиболее вероятный вариант\n",
        "    return analyses[0].normal_form\n",
        "\n",
        "# Пример с омонимами\n",
        "print(f\"'стекло' как глагол: {smart_lemmatize('стекло', 'VERB')}\")\n",
        "print(f\"'стекло' как существительное: {smart_lemmatize('стекло', 'NOUN')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irX1ScY_FOFb",
        "outputId": "e8415e70-ba93-4ead-d5ed-d9876805bbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'стекло' как глагол: стечь\n",
            "'стекло' как существительное: стекло\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работа с грамматическими тегами в кириллице"
      ],
      "metadata": {
        "id": "x6ORTYXaFamm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detailed_analysis(word):\n",
        "    parsed = morph.parse(word)[0]\n",
        "\n",
        "    print(f\"Детальный разбор слова '{word}':\")\n",
        "    print(f\"Лемма: {parsed.normal_form}\")\n",
        "    print(f\"Часть речи: {parsed.tag.POS}\")\n",
        "    print(f\"Морфологические признаки:\")\n",
        "\n",
        "    # Все доступные признаки\n",
        "    tag_dict = parsed.tag.cyr_repr  # Кириллическое представление\n",
        "    print(tag_dict)\n",
        "\n",
        "detailed_analysis(\"писавшему\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgYftKWgFv_C",
        "outputId": "e0c85cdf-7416-4b6c-ec8a-18811ee302c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Детальный разбор слова 'писавшему':\n",
            "Лемма: писать\n",
            "Часть речи: PRTF\n",
            "Морфологические признаки:\n",
            "ПРИЧ,несов,неперех,прош,действ мр,ед,дт\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фильтрация по грамматическим признакам"
      ],
      "metadata": {
        "id": "-soQUinWF2qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_by_pos(text, target_pos):\n",
        "    words = text.split()\n",
        "    result = []\n",
        "\n",
        "    for word in words:\n",
        "        clean_word = ''.join(char for char in word if char.isalpha())\n",
        "        if clean_word:\n",
        "            parsed = morph.parse(clean_word)[0]\n",
        "            if parsed.tag.POS == target_pos:\n",
        "                result.append({\n",
        "                    'word': clean_word,\n",
        "                    'lemma': parsed.normal_form,\n",
        "                    'features': str(parsed.tag)\n",
        "                })\n",
        "\n",
        "    return result\n",
        "\n",
        "text = \"Рыжая кошка сидела на окне и смотрела на улицу\"\n",
        "\n",
        "print(\"Существительные:\")\n",
        "nouns = extract_by_pos(text, 'NOUN')\n",
        "for noun in nouns:\n",
        "    print(f\"  {noun}\")\n",
        "\n",
        "print(\"\\nГлаголы:\")\n",
        "verbs = extract_by_pos(text, 'VERB')\n",
        "for verb in verbs:\n",
        "    print(f\"  {verb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t7YddwqGAuo",
        "outputId": "5a999ea2-42c9-44d2-93ae-a1bc5ab5a11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Существительные:\n",
            "  {'word': 'кошка', 'lemma': 'кошка', 'features': 'NOUN,anim,femn sing,nomn'}\n",
            "  {'word': 'окне', 'lemma': 'окно', 'features': 'NOUN,inan,neut sing,loct'}\n",
            "  {'word': 'улицу', 'lemma': 'улица', 'features': 'NOUN,inan,femn sing,accs'}\n",
            "\n",
            "Глаголы:\n",
            "  {'word': 'сидела', 'lemma': 'сидеть', 'features': 'VERB,impf,intr femn,sing,past,indc'}\n",
            "  {'word': 'смотрела', 'lemma': 'смотреть', 'features': 'VERB,impf,tran femn,sing,past,indc'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск слов с определенными характеристиками"
      ],
      "metadata": {
        "id": "Ue-Yyok-GJe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_words_with_features(text, **features):\n",
        "    words = text.split()\n",
        "    matches = []\n",
        "\n",
        "    for word in words:\n",
        "        clean_word = ''.join(char for char in word if char.isalpha())\n",
        "        if clean_word:\n",
        "            parsed = morph.parse(clean_word)[0]\n",
        "            match = True\n",
        "\n",
        "            for feature, value in features.items():\n",
        "                if getattr(parsed.tag, feature, None) != value:\n",
        "                    match = False\n",
        "                    break\n",
        "\n",
        "            if match:\n",
        "                matches.append(parsed.word)\n",
        "\n",
        "    return matches\n",
        "\n",
        "text = \"Лохматые собаки бежали по узкому тротуару\"\n",
        "\n",
        "# Поиск существительных в именительном падеже\n",
        "nominative_nouns = find_words_with_features(text, POS='NOUN', case='nomn')\n",
        "print(f\"Существительные в им.падеже: {nominative_nouns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3y5WlRtGOIl",
        "outputId": "407d73ff-b43b-4c11-a1b6-c0ccb834dca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Существительные в им.падеже: ['собаки']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Анализ текста целиком"
      ],
      "metadata": {
        "id": "75qEO8emGZWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_morph_analysis(text):\n",
        "    words = [''.join(char for char in word if char.isalpha())\n",
        "            for word in text.split()]\n",
        "\n",
        "    analysis = {\n",
        "        'total_words': len(words),\n",
        "        'unique_lemmas': set(),\n",
        "        'pos_distribution': {},\n",
        "        'words': []\n",
        "    }\n",
        "\n",
        "    for word in words:\n",
        "        parsed = morph.parse(word)[0]\n",
        "        analysis['unique_lemmas'].add(parsed.normal_form)\n",
        "\n",
        "        pos = str(parsed.tag.POS)\n",
        "        analysis['pos_distribution'][pos] = analysis['pos_distribution'].get(pos, 0) + 1\n",
        "\n",
        "        analysis['words'].append({\n",
        "            'word': word,\n",
        "            'lemma': parsed.normal_form,\n",
        "            'pos': pos,\n",
        "            'features': parsed.tag.cyr_repr\n",
        "        })\n",
        "\n",
        "    analysis['unique_lemmas'] = len(analysis['unique_lemmas'])\n",
        "    return analysis\n",
        "\n",
        "sample_text = \"Шёл я по улице незнакомой и вдруг услышал вороний грай, и звоны лютни, и дальние громы, передо мною летел трамвай.\"\n",
        "result = text_morph_analysis(sample_text)\n",
        "\n",
        "print(f\"Общее количество слов: {result['total_words']}\")\n",
        "print(f\"Уникальных лемм: {result['unique_lemmas']}\")\n",
        "print(f\"Распределение по частям речи: {result['pos_distribution']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSJEsNkVGfD4",
        "outputId": "7906c907-1937-4a0f-815f-c0d3ae0f1949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общее количество слов: 20\n",
            "Уникальных лемм: 17\n",
            "Распределение по частям речи: {'VERB': 3, 'NPRO': 2, 'PREP': 2, 'NOUN': 6, 'ADJF': 3, 'CONJ': 3, 'ADVB': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравнение текстов"
      ],
      "metadata": {
        "id": "KWyHVmmvHlrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_texts(text1, text2):\n",
        "    analysis1 = text_morph_analysis(text1)\n",
        "    analysis2 = text_morph_analysis(text2)\n",
        "\n",
        "    print(\"Сравнение текстов:\")\n",
        "    print(f\"Лексическое разнообразие:\")\n",
        "    print(f\"  Текст 1: {analysis1['unique_lemmas']/analysis1['total_words']:.3f}\")\n",
        "    print(f\"  Текст 2: {analysis2['unique_lemmas']/analysis2['total_words']:.3f}\")\n",
        "\n",
        "    print(f\"Распределение частей речи:\")\n",
        "    for pos in set(analysis1['pos_distribution']) | set(analysis2['pos_distribution']):\n",
        "        count1 = analysis1['pos_distribution'].get(pos, 0)\n",
        "        count2 = analysis2['pos_distribution'].get(pos, 0)\n",
        "        print(f\"  {pos}: {count1} vs {count2}\")\n",
        "\n",
        "text1 = \"Как я вскочил на его подножку, было загадкою для меня, в воздухе огненную дорожку он оставлял при свете дня.\"\n",
        "text2 = \"Мчался он бурей тёмной, крылатой, он заблудился в бездне времён. Остановите, вагоновожатый, остановите сейчас вагон!\"\n",
        "\n",
        "compare_texts(text1, text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0XcTVdxHqlp",
        "outputId": "c66ad32c-4f01-426f-d9da-ae5a818d2e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сравнение текстов:\n",
            "Лексическое разнообразие:\n",
            "  Текст 1: 0.895\n",
            "  Текст 2: 0.867\n",
            "Распределение частей речи:\n",
            "  ADVB: 0 vs 1\n",
            "  ADJF: 1 vs 2\n",
            "  VERB: 3 vs 4\n",
            "  NPRO: 4 vs 2\n",
            "  PREP: 4 vs 1\n",
            "  CONJ: 1 vs 0\n",
            "  NOUN: 6 vs 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1.\n",
        "Проанализировать любой русский текст\n",
        "\n",
        "1. Найти все глаголы в прошедшем времени\n",
        "2. Выделить все существительные в дательном падеже\n",
        "3. Посчитать лексическое разнообразие текста\n",
        "4. Найти все прилагательные в превосходной степени\n",
        "5. Создать частотный словарь лемм\n"
      ],
      "metadata": {
        "id": "vsv-sCTQIYar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r\"1.txt\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "\n",
        "text = \" \".join(line.strip() for line in lines)\n",
        "\n",
        "import pymorphy3\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "def find_words_with_features(text, **features):\n",
        "    words = text.split()\n",
        "    matches = []\n",
        "\n",
        "    for word in words:\n",
        "        clean_word = ''.join(char for char in word if char.isalpha())\n",
        "        if clean_word:\n",
        "            parsed = morph.parse(clean_word)[0]\n",
        "            match = True\n",
        "\n",
        "            for feature, value in features.items():\n",
        "                if getattr(parsed.tag, feature, None) != value:\n",
        "                    match = False\n",
        "                    break\n",
        "\n",
        "            if match:\n",
        "                matches.append(parsed.word)\n",
        "\n",
        "    return matches\n",
        "\n",
        "# Найти все глаголы в прошедшем времени\n",
        "past_tense_verbs = find_words_with_features(text, POS='VERB', tense='past')\n",
        "print(past_tense_verbs)\n",
        "\n",
        "# Выделить все существительные в дательном падеже\n",
        "dative_nouns = find_words_with_features(text, POS='NOUN', case='datv')\n",
        "print(dative_nouns)\n",
        "\n",
        "# Посчитать лексическое разнообразие текста\n",
        "unique_lemmas = set()\n",
        "words = [''.join(char for char in word if char.isalpha())\n",
        "            for word in text.split()]\n",
        "\n",
        "for word in words:\n",
        "    if len(word.strip()) > 0:\n",
        "        lemma = morph.parse(word)[0].normal_form\n",
        "        unique_lemmas.add(lemma)\n",
        "\n",
        "print(len(unique_lemmas) / len(words))\n",
        "\n",
        "# Найти все прилагательные в превосходной степени\n",
        "adjectives = \"красивый умнейший сильнее быстрейший\"\n",
        "adj_list = adjectives.split()\n",
        "supr_adj = []\n",
        "for adj in adj_list:\n",
        "    if \"Supr\" in morph.parse(adj)[0].tag:\n",
        "        supr_adj.append(adj)\n",
        "\n",
        "print(supr_adj)\n",
        "\n",
        "# Создать частотный словарь лемм\n",
        "lemmas_dict = {}\n",
        "\n",
        "words_lemmatized = [morph.parse(word)[0].normal_form for word in words]\n",
        "for lemma in unique_lemmas:\n",
        "    lemmas_dict[lemma] = words_lemmatized.count(lemma)\n",
        "\n",
        "print(lemmas_dict)\n",
        "\n"
      ],
      "metadata": {
        "id": "5OH_o_EJIlE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание морфологического профиля текста"
      ],
      "metadata": {
        "id": "magDW-7ZImHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_morph_profile(text):\n",
        "    \"\"\"\n",
        "    Создает морфологический профиль текста, включающий:\n",
        "    - распределение частей речи\n",
        "    - разнообразие падежей\n",
        "    - разнообразие времен глаголов\n",
        "    - и другие морфологические характеристики\n",
        "    \"\"\"\n",
        "    morph = pymorphy3.MorphAnalyzer()\n",
        "    words = [word.strip('.,!?;:()\"\"') for word in text.split() if word.strip('.,!?;:()\"\"')]\n",
        "\n",
        "    profile = {\n",
        "        'total_words': len(words),\n",
        "        'pos_distribution': {},\n",
        "        'case_diversity': {},\n",
        "        'verb_tense': {},\n",
        "        'number_distribution': {},\n",
        "        'gender_distribution': {},\n",
        "        'unique_lemmas': set(),\n",
        "        'word_forms_per_lemma': {}\n",
        "    }\n",
        "\n",
        "    for word in words:\n",
        "        parsed = morph.parse(word)[0]  # Берем наиболее вероятный разбор\n",
        "\n",
        "        # Часть речи\n",
        "        pos = str(parsed.tag.POS)\n",
        "        profile['pos_distribution'][pos] = profile['pos_distribution'].get(pos, 0) + 1\n",
        "\n",
        "        # Падежи (для склоняемых частей речи)\n",
        "        case = str(parsed.tag.case)\n",
        "        if case != 'None':\n",
        "            profile['case_diversity'][case] = profile['case_diversity'].get(case, 0) + 1\n",
        "\n",
        "        # Время глаголов\n",
        "        tense = str(parsed.tag.tense)\n",
        "        if tense != 'None':\n",
        "            profile['verb_tense'][tense] = profile['verb_tense'].get(tense, 0) + 1\n",
        "\n",
        "        # Число\n",
        "        number = str(parsed.tag.number)\n",
        "        if number != 'None':\n",
        "            profile['number_distribution'][number] = profile['number_distribution'].get(number, 0) + 1\n",
        "\n",
        "        # Род\n",
        "        gender = str(parsed.tag.gender)\n",
        "        if gender != 'None':\n",
        "            profile['gender_distribution'][gender] = profile['gender_distribution'].get(gender, 0) + 1\n",
        "\n",
        "        # Леммы и словоформы\n",
        "        lemma = parsed.normal_form\n",
        "        profile['unique_lemmas'].add(lemma)\n",
        "        if lemma not in profile['word_forms_per_lemma']:\n",
        "            profile['word_forms_per_lemma'][lemma] = set()\n",
        "        profile['word_forms_per_lemma'][lemma].add(word)\n",
        "\n",
        "    return profile\n",
        "\n",
        "# Тестовый текст\n",
        "test_text = \"\"\"\n",
        "Поздно. Уж обогнули мы стену, мы проскочили сквозь рощу пальм, через Неву, через Нил или Сену мы прогремели по трём мостам.\n",
        "\"\"\"\n",
        "\n",
        "profile = create_morph_profile(test_text)\n",
        "print(\"Морфологический профиль текста:\")\n",
        "for key, value in profile.items():\n",
        "    if key != 'word_forms_per_lemma':\n",
        "        print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8SGaU8yJUQ5",
        "outputId": "20cca73b-61e7-4d1b-d467-9141ff90f710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Морфологический профиль текста:\n",
            "total_words: 21\n",
            "pos_distribution: {'ADVB': 2, 'VERB': 3, 'NPRO': 3, 'NOUN': 7, 'PREP': 4, 'CONJ': 1, 'NUMR': 1}\n",
            "case_diversity: {'nomn': 4, 'accs': 3, 'gent': 1, 'datv': 3}\n",
            "verb_tense: {'past': 3}\n",
            "number_distribution: {'plur': 8, 'sing': 5}\n",
            "gender_distribution: {'femn': 4, 'masc': 2, 'neut': 1}\n",
            "unique_lemmas: {'по', 'поздно', 'нил', 'сено', 'три', 'пальма', 'проскочить', 'обогнуть', 'уж', 'мост', 'мы', 'сквозь', 'стена', 'роща', 'через', 'или', 'прогреметь', 'нева'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание. Найдите три текста примерно одинаковой длины: художественный (рассказ или отрывок), научный (статья или учебник), разговорный (диалоги из фильма или интервью).\n",
        "\n",
        "Проведите анализ для каждого текста: постройте морфологический профиль.\n",
        "\n",
        "Какой текст самый сложный морфологически и почему?\n",
        "\n",
        "Какие особенности каждого стиля отражаются в морфологических показателях?"
      ],
      "metadata": {
        "id": "FgQj-6LINu5_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a61qW2SmOL72"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}